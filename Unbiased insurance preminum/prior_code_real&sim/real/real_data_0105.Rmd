---
title: "Real Data Analysis"
author : 232STG08 박민정 
output: html_document
---

```{r, warning=FALSE}
setwd("C:/Users/none/Desktop/대학원/논문/data")
source("repeated_data_management.R") 
library(tidyverse)
library(nimble)
library(MCMCvis)
```

```{r}
summary(data.train)
#dim(data)
#dim(dataout)
dim(data.train)
dim(data.valid)
```


## Unique한 ID에 대해 순서 매기기

> **id_uniq** : data.train의 ID 중, 고유값만 뽑아낸 벡터 (길이 : 409) <br/>
> **id_idx** : data.train의 ID를 고유 ID의 순번으로 대체한 벡터 (길이 : 1467) <br/>

```{r}
# data.train 데이터의 사람 총 409명
id_uniq = unique(data.train$PolicyNum)
length(id_uniq)


id_idx=c(NULL)

for(i in 1:length(id_uniq)){
  # data.train에 해당 id가 몇 행 있는지 체크
  ind = id_uniq[i] == data.train$PolicyNum 
  # data.train에 존재하는 데이터 수 만큼 순번을 반복 출력 후 변수에 저장
  id_idx=c(id_idx, rep(i, sum(ind)))
}

head(id_idx, 20)    
tail(id_idx, 20) 
length(id_idx)
```



## ID당 Coverage 달라질 경우 최빈값으로 통일하기

> **cov.data.train** : coverage 최빈값 계산을 위해 필요한 데이터만 추출한 데이터 프레임 (1467 x 3) <br/>
> **cov.new.train** : 최빈값으로 대체한 new coverage 벡터 (길이 : 1467) <br/>
> **cov.id_idx** : 최빈값을 계산하기 위해 해당 unique ID의 coverage를 추출한 데이터 프레임 (unique ID의 데이터 수 마다 행 개수 바뀜) <br/>


```{r}
cov.data.train <- cbind(id_idx, data.train[,c("PolicyNum", "col.Cov.Idx")])
cov.new.train <- rep(0, nrow(cov.data.train))

# Coverage 달라지는 경우 각각의 고유 ID에 대해 최빈값으로 채워넣기
for (i in 1:nrow(cov.data.train)){
  cov.id_idx <- cov.data.train %>% filter (id_idx==cov.data.train[i,"id_idx"]) %>% select(col.Cov.Idx)
  cov.new.train[i] <- as.numeric(names(which.max(table(cov.id_idx$col.Cov.Idx))))
}

# 새로운 coverage 값으로 replace
data.train$col.Cov.Idx <- cov.new.train

# 범주형 변수 인코딩
data.train$C2  <- ifelse(data.train$col.Cov.Idx==1, 1, 0)
data.train$C3  <- ifelse(data.train$col.Cov.Idx==2, 1, 0)
```



## a.hat, lambda.hat, R, beta.hat 추정 (nimble)

```{r}
# design matrix 만들기
X = model.matrix(n~TypeCity+TypeCounty+TypeSchool+TypeTown+TypeVillage+C2+C3, data = data.train)


model <- nimbleCode({
  
  # likelihood
  for(j in 1:JJ){
    lambda[j] <-exp(inprod(X[j,1:KK], beta.hat[1:KK]))
    y[j] ~ dnegbin(prob = k.hat/(k.hat+lambda[j]*R[id_idx[j]]), size = k.hat)
  }
  
  # prior of R
  for(n in 1:N.id_idx){
    R[n] ~ dgamma(mean=1, sd=1/a.hat)
  }
  
  # prior of Betas (params 개수 만큼 추출)
  for(j in 1:KK){
    beta.hat[j] ~ dnorm(mean=0, sd=10)
  } 
  
  # prior of alpha
  a.hat ~ dunif(min=0, max=10)
  k.hat ~ dunif(min=0, max=10)
})


my.data <- list(X = X, y = data.train$n)
my.constants <- list(JJ=dim(X)[1], KK=dim(X)[2], id_idx=id_idx, N.id_idx=max(id_idx))
parameters.to.save <- c("beta.hat", "a.hat", "lambda", "R", "k.hat")


my_model <- nimbleModel(code = model, name = "my_model", constants = my.constants, data = my.data)
Cmy_model  <- compileNimble(my_model)
my_modelConf <- configureMCMC(my_model, print = TRUE)
my_modelConf$addMonitors('beta.hat', "a.hat", "lambda", "R", "k.hat")
MCMC <- buildMCMC(my_modelConf)
CMCMC <- compileNimble(MCMC, project = my_model)


n.iter <- 12000
n.burnin <- 2000
n.chains <- 2

set.seed(123)
samples <- runMCMC(CMCMC, niter = n.iter,
                   nburnin = n.burnin,
                   nchains = n.chains)

MCMCtrace(object = samples,
          pdf = FALSE, # no export to PDF
          ind = TRUE, # separate density lines per chain
          params = "beta.hat")

MCMCtrace(object = samples,
          pdf = FALSE, # no export to PDF
          ind = TRUE, # separate density lines per chain
          params = "a.hat")

MCMCtrace(object = samples,
          pdf = FALSE, # no export to PDF
          ind = TRUE, # separate density lines per chain
          params = "k.hat")
```


## nimble 시행 결과 저장

> **samples** : chain1, chain2에 list형식으로 각각 저장된 nimble 결과 원본 <br/>

> **result** : 각 parameter의 summary 값을 저장한 데이터 프레임 (1885 x 7) <br/>
> **nrow(result)** : 추정하고 싶은 parameter 총 1885개 (R 409개 + a 1개 + beta 8개 + lambda 1467개) <br/>
> **ncol(result)** : 통계량 총 7개 (Rhat, n.eff는 뭔지 모르겠음) <br/>

> **R** : 각 ID의 R 추정치 벡터 , 10000개 sample의 평균치 사용한 방법 (길이 : 409) <br/>
> *R은 앞으로 사용 X (평균 사용 안하고 sampling)* <br/>

> **a.hat** : gamma dist의 parameter a의 추정치 상수 (길이 : 1) <br/>
> **beta.hat** : lambda = exp(XB) 추정을 위한 X 계수 추정치 벡터 (길이 : 8) <br/>
> **lambda.hat** : 위와 같이 계산된 lambda 추정치 벡터, 고유 ID에 대한 값은 동일해야함 (길이 : 1467) <br/>
> **lambda_uq** : 각 ID에 대해 unique한 lambda를 가지는지 확인하기 위한 데이터 프레임 (1467 x 3) <br/>



```{r}
# chain 1에 대해 저장된 param들의 sample data 구조 살펴보기
# 추정하고 싶은 parameter 개수 총 1885개
str(samples[[1]])

# 각 parameter 별로 10000개 sample에 대해 mean 취할 때 2자리 수 반올림
result <- MCMCsummary(object = samples, round = 2)
head(result)
dim(result)

# save estimated params
R <- result[1:409,1] ;R #409
a.hat <- result[410,1] ;a.hat #1
beta.hat <-  result[411:418,1] ;beta.hat #8
k.hat <- result[419,1] #1

lambda.hat <- result[420:1886,1] #1467
summary(lambda.hat)
table(lambda.hat)



# 각 ID에 대해 unique한 lambda를 가지는지 확인
# ID, id_idx, lambda.hat에 대해 unique한 행을 추출하여 행 개수가 id_uniq의 길이와 같으면 정상
lambda_uq = unique(cbind(data.train$PolicyNum, id_idx, lambda.hat)) 
nrow(lambda_uq)
head(lambda_uq)
```



## 409개 R의 10000개 sample에대해 추출

> **R.hat** : NA값 대체를 위한 각 ID의 R값 벡터 (길이 : 409) <br/>
> *평균을 취하는 것이 아닌, nimble로 R[id_uniqe]에 대해 각각 generate한 10000개의 sample 중 1개를 random select* <br/>

```{r}
set.seed(123)

# 각 ID에 해당하는 10000개의 sample 중 1개 random 셀렉
# chain 1만 사용
R.hat <- rep(0, 409)

for(i in 1:409){
  R.hat[i] <- sample(samples$chain1[,paste0("R[", i, "]")],1)
}
```


## 결측치 채우기

> **lam_vec** : 모든 data에 대해 추정한 lambda.hat 벡터 (길이 : 1497) <br/>
> **lambs** : 추정한 lambda.hat의 unique 값 벡터 (길이 : 17) <br/>
> **lam_pol** : 각 ID의 lambda.hat값을 저장한 벡터 (길이 : 409) <br/>
> **Y** : 각 ID 별 Y_1 ~ Y_5 데이터 프레임 (409 x 6) <br/>

```{r}
N_sim = length(id_uniq)
tau = length(unique(data.train$Year)); n_model = 3
k = k.hat # NB의 dispersion param
a  = a.hat #Gamma의 param

lam_vec = lambda.hat #1497
lambs <- unique(lam_vec) #17
lam_pol <- lambda_uq[,3] #409 

## Risk group에 속한 비율 !!! ##
round(table(lam_pol)/409,3)


# Y 구성
Y = data.frame(matrix(nrow = length(id_uniq), ncol = tau))

# 여기 코드 돌아가는 원리 모르겠음 !!
for(i in 1:length(id_uniq)){
  Y[i,tau+1] = id_uniq[i]
  ys = data.train[data.train$PolicyNum == id_uniq[i], ]$n
  for(j in 1: length(ys)){
    Y[i,j] = ys[j]
  }
}
#Y$n <- data.valid$n # target은 이름이 n인 열로 구성

colnames(Y) <- c("y_1", "y_2", "y_3",  "y_4", "y_5", "ID")
Y
original_Y = Y
```


> dnbinom의 size : dispersion parameter, 즉 k와 같다 <br/>
> dnbinom의 prob : size/(size+mu) <br/>

```{r}
set.seed(123)

# 결측치 채우기
for (i in 1:nrow(Y)){
  for (j in 1:tau){
    if (is.na(Y[i,j])==TRUE)
      Y[i,j] = rnbinom(1,prob = k/(k+lam_pol[i]*R.hat[i]), size = k)}
}
Y #최종 Y
```



## 최종 Data frame 만들기

> **Y.df** : 각 ID별 lambda, R, y값들을 모은 데이터 프레임 (409 x 7) <br/>
> <span style='background-color: #fff5b1'>변수명 변경 하면 좋을 것 같음 뒤에서 코드 돌리기 편한 변수명으로 !</span> <br/>


```{r}
Y.df <- data.frame(cbind(Y[,6], lam_pol, R.hat, Y[,1:5]))
colnames(Y.df) <- c("ID", "lambda", "R", "y_1", "y_2", "y_3", "y_4", "y_5")

head(Y.df, 20)

# 결측치가 적절하게 채워진건지 check
cbind(original_Y[,-6], Y.df)
```


## data.valid 기준 lambda table 만들기


```{r}
idx = unique(data.train$PolicyNum) %in% data.valid$PolicyNum

YY <- Y.df[idx, ]

table(YY$lambda)
round(table(YY$lambda)/253, 3)

```




#########################################################

```{r, eval=F}
### Task 2) Comparing MSE & Biasedness of 3 Models

##함수 정의

# -------------------------------------------------------------------------------
# 필요 함수 정의 (proposition coeff, Yhat)
# -------------------------------------------------------------------------------

# 각 모델의 optm값( 즉 model3의 경우 alpha0, alpha1 // model2의 경우 alpha0) 계산에 이용되는 값 계산
# E_ysq, E_lam_ysq, E_lamsq_ysq, E_lamsq_ybar, E_lamsq_ybarsq, E_lam_y, E_lamsq_y, E_lam_y_ybar, E_lamsq_y_ybar
prop_coeff <- function(lam_vec, a, tau, k){
  #E_ysq = var(u_lam_R) + mean(v_lam_R) + mean(u_lam_R)^2
  E_lam_vec    = mean(lam_vec)
  E_lam_vec_sq = mean(lam_vec^2)
  E_lam_vec_th = mean(lam_vec^3)
  E_lam_vec_for = mean(lam_vec^4)
  
  E_ysq0          = E_lam_vec_sq + E_lam_vec + 1/k * E_lam_vec_sq * (1/a+1)
  E_lam_ysq0      = E_lam_vec_sq + 1/k * E_lam_vec_th * (1+1/a) + E_lam_vec_sq
  E_lamsq_ysq0    = E_lam_vec_th + 1/k * E_lam_vec_for * (1+1/a) + E_lam_vec_th
  E_lamsq_ybar0   = E_lam_vec_th
  E_lamsq_ybarsq0 = 1/tau * E_lam_vec_th + 1/(2*k) * E_lam_vec_for * (1+1/a) + E_lam_vec_for * (1+1/a)
  E_lam_y0       = E_lam_vec_sq
  E_lamsq_y0      = E_lam_vec_th
  E_lam_y_ybar0   = E_lam_vec_th * (1/a + 1)
  E_lamsq_y_ybar0 = E_lam_vec_for * (1+1/a)
  E_lam_ybarsq0 = 1/tau * E_lam_vec_sq + 1/(2*k) * E_lam_vec_th * (1+1/a) + E_lam_vec_th * (1+1/a)
  E_lamth_ybar0 = E_lam_vec_for
  E_lamth_y0    = E_lam_vec_for
  
  return (c(E_ysq = E_ysq0, E_lam_ysq = E_lam_ysq0, E_lamsq_ysq = E_lamsq_ysq0, E_lamsq_ybar = E_lamsq_ybar0, 
            E_lamsq_ybarsq = E_lamsq_ybarsq0, E_lam_y = E_lam_y0, E_lamsq_y = E_lamsq_y0, E_lam_y_ybar = E_lam_y_ybar0,
            E_lamsq_y_ybar = E_lamsq_y_ybar0, E_lam_ybarsq= E_lam_ybarsq0, E_lamth_ybar = E_lamth_ybar0, E_lamth_y = E_lamth_y0))
}


Yhat_ftn <- function( N_sim, n_model, tau, lam_vec, Y, m2_alpha0, m2_alpha1, m3_alpha0){
  Yhat = data.frame(matrix(nrow = N_sim, ncol = n_model))
  
  # model 1,2,3 y_hat값 생성
  for(n in 1: N_sim){
    Yhat[n,1] = lam_vec[n] * (a+sum(Y[n,1:tau]))/(a+tau*lam_vec[n])
    Yhat[n,2] = lam_vec[n] * (m2_alpha0 + m2_alpha1 * sum(Y[n,1:tau])/tau)
    Yhat[n,3] = lam_vec[n]/(m3_alpha0 + (1- m3_alpha0) * lam_vec[n]) * ( m3_alpha0 + (1- m3_alpha0) * sum(Y[n,1:tau])/tau)
  }
  return( Yhat )
}


cal_mse <- function(n_model, y_true = Y[,6]){
  mse = data.frame(matrix(nrow = 1, ncol = n_model))
  for(j in 1: n_model){
    mse[1,j] = mean((Yhat[,j]-y_true)^2)
  }
  return( mse )
}


# 각 모델별 unbiasedness 계산

#lam_pol : PolicyNum 한명의 고유한 lambda.hat (총 409개)
cal_UB <- function(lambs, n_model,Yhat, lam_pol){
  E_y_given_lam <- data.frame(matrix(nrow = length(lambs), ncol = n_model+1))
  
  total <- Yhat
  total$lam_pol <- lam_pol # tmp <- cbind(Yhat, lam_vec)이건 왜 안됨..?
  for( i in 1: length(lambs)){
    E_y_given_lam[i,] = apply(total[total$lam_pol == lambs[i],],2,mean) # 각 모델의 lamb별 평균
  }
  
  total_unbiasedness_ch = apply((E_y_given_lam[,1:n_model]-lambs)^2/lambs,2,sum)
  return(total_unbiasedness_ch)
}




##############################################



# 각 모델에 대한 mod2의 알파0,알파1과 mod3의 알파0 계산
P <- prop_coeff(lam_vec, a, tau, k)

m2_alpha1 = (P["E_lam_y"] * P["E_lamsq_ybar"] - P["E_lam_y_ybar"] * mean(lam_vec^2))       /(P["E_lamsq_ybar"]^2-P["E_lamsq_ybarsq"]*mean(lam_vec^2))
m2_alpha0 = (P["E_lamsq_ybar"] * P["E_lam_y_ybar"] - P["E_lam_y"] * P["E_lamsq_ybarsq"])/(P["E_lamsq_ybar"]^2-P["E_lamsq_ybarsq"]*mean(lam_vec^2))

# m3에 대한 alpha0 
m3_alpha0_n = P["E_lamsq_y_ybar"] - P["E_lamth_y"] - P["E_lamsq_ybarsq"] + P["E_lamth_ybar"]
m3_alpha0_d = P["E_lam_y_ybar"] - P["E_lamsq_y_ybar"] - P["E_lamsq_ybar"] + P["E_lamsq_ybarsq"] - P["E_lamsq_y"]  + P["E_lamth_y"] + mean(lam_vec^3) - P["E_lamth_ybar"]

m3_alpha0 = - m3_alpha0_n/m3_alpha0_d


# 각 모델별 예측값 추출 
Yhat <- Yhat_ftn( N_sim, n_model, tau, lam_vec, Y, m2_alpha0, m2_alpha1, m3_alpha0)

# MSE 계산
mse_model <- cal_mse(n_model, y_true = Y[,tau+1])

# 각 모델별 unbiasedness 확인
total_unbiasedness_ch <- cal_UB(lambs,n_model,Yhat, lam_vec)

total_unbiasedness_ch
```

